{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAGE_URL = 'https://www.rusprofile.ru/codes/620000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    \"\"\"Makes tasty soup out of raw HTML\"\"\"\n",
    "    return soup(requests.get(url).text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Number of Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages to scrape from: 964\n"
     ]
    }
   ],
   "source": [
    "base_page_soup = get_soup(PAGE_URL) # get page soup to extract n of pages\n",
    "pg_list = base_page_soup.find('ul', class_=\"paging-list\") # find pagination item on the page\n",
    "N_PAGES = int(pg_list.find_all('li')[-2].text)\n",
    "iterator_arg = range(1, N_PAGES + 1) # define iterator for browsing pages\n",
    "print(f'Total pages to scrape from: {N_PAGES}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scapping functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_companies(page_soup):\n",
    "    \"\"\"Finds companies on the page. Returns tags list\"\"\"\n",
    "    return page_soup.find_all('div', class_ = 'company-item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_dict = {\n",
    "    'января' : 1, 'февраля' : 2, 'марта' : 3, 'апреля' : 4, 'мая' : 5, 'июня' : 6,\n",
    "    'июля' : 7, 'августа' : 8, 'сентября' : 9, 'октября' : 10, 'ноября' : 11, 'декабря' : 12\n",
    "} # dictionary for transferring russian names into integer months numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_company(company):\n",
    "    \"\"\"Extracts data from each company item\"\"\"\n",
    "    company_name = company.find('div', class_=\"company-item__title\").find('a').text.strip()\n",
    "    try:\n",
    "        company_status = company.find('span', class_=\"warning-text\").text.strip()\n",
    "    except:\n",
    "        company_status = 'Организация работает'\n",
    "    company_address = ', '.join(company.find('address',  class_=\"company-item__text\").text.strip().split(', ')[1:4])\n",
    "    lst = company.findAll('div', class_='company-item-info')[1].findAll('dd')\n",
    "    find_date = [i for i in lst if 'г.' in i]\n",
    "    find_cap = [i for i in lst if 'руб.' in i]\n",
    "    if len(find_date) != 0:\n",
    "        company_estdate = find_date[0].strip(' г.').split(' ')\n",
    "        company_estdate = pd.Timestamp(f'{company_estdate[2]}-{month_dict[company_estdate[1]]}-{company_estdate[0]}')\n",
    "    else:\n",
    "        company_estdate = None\n",
    "        \n",
    "    if len(find_cap) != 0:\n",
    "        company_cap = pd.to_numeric(find_cap[0].strip(' руб.').replace(' ', '').replace(',', '.'))\n",
    "    else:\n",
    "        company_cap = None\n",
    "    company_activity = company.findAll('div',  class_=\"company-item-info\")[-1].find('dd').text.strip()\n",
    "    return pd.Series({'name' : company_name, 'status' : company_status,\n",
    "                      'address' : company_address, 'est_date' : company_estdate,\n",
    "                      'cap' : company_cap, 'activity' : company_activity})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_url_iterable = PAGE_URL + '/{}/' # Making the string changable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_num = PAGE_URL.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLEEP_TIME = 5 # Essential! Could be increased manually if needed. Defines pause betweeen opening the pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for page_n in tqdm(iterator_arg):\n",
    "    current_page_soup = get_soup(page_url_iterable.format(page_n))\n",
    "    sleep(SLEEP_TIME)\n",
    "    companies = get_companies(current_page_soup)\n",
    "    current_page_df = pd.DataFrame([scrape_company(company) for company in companies])\n",
    "    df_list.append(current_page_df)\n",
    "    \n",
    "full_cat_df = pd.concat(df_list)\n",
    "full_cat_df = full_cat_df.assign(base_category = int(cat_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cat_df = full_cat_df[full_cat_df.activity.str.contains(cat_num[:2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_cat_df.to_csv(f'data/database_{cat_num}.csv', index = None, encoding = 'utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
